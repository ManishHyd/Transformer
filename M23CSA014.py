# -*- coding: utf-8 -*-
"""M23CSA014_DL Assignment 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_rDf0tQt--dU7521PZ7PjuPpl_rg_dg2
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Installing the requirements
print('Installing Requirements... ',end='')
# %pip install lightning
# %pip install wandb
print('Done')

# Importing Libraries
print('Importing Libraries... ',end='')
import os
from pathlib import Path
import pandas as pd
import torchaudio
import zipfile
from torchaudio.transforms import Resample
import IPython.display as ipd
from matplotlib import pyplot as plt
from tqdm import tqdm
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
import torch
from statistics import mean, median
print('Done')

# Extract data
with zipfile.ZipFile("/content/drive/MyDrive/Archive.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/")

# Loading dataset
path = Path('/content/')
df = pd.read_csv('/content/meta/esc50.csv')

# # Loading dataset
# path = Path('/teamspace/studios/this_studio/assign1')
# df = pd.read_csv('/teamspace/studios/this_studio/assign1/meta/esc50.csv')

# Getting list of raw audio files
wavs = list(path.glob('audio/*'))  # List all audio files in the 'audio' directory using pathlib.Path.glob

# Visualizing data
waveform, sample_rate = torchaudio.load(str(wavs[0])) # Load the waveform and sample rate of the first audio file using torchaudio

print("Shape of waveform: {}".format(waveform.size()))  # Print the shape of the waveform tensor
print("Sample rate of waveform: {}".format(sample_rate))  # Print the sample rate of the audio file

# Plot the waveform using matplotlib
plt.figure()
plt.plot(waveform.t().numpy())  # Transpose and convert the waveform tensor to a NumPy array for plotting

# Display the audio using IPython.display.Audio
ipd.Audio(waveform, rate=sample_rate)  # Create an interactive audio player for the loaded waveform

class CustomDataset(Dataset):
    def __init__(self, dataset, **kwargs):
        # Initialize CustomDataset object with relevant parameters
        # dataset: "train", "val", or "test"
        # kwargs: Additional parameters like data directory, dataframe, folds, etc.

        # Extract parameters from kwargs
        self.data_directory = kwargs["data_directory"]
        self.data_frame = kwargs["data_frame"]
        self.validation_fold = kwargs["validation_fold"]
        self.testing_fold = kwargs["testing_fold"]
        self.esc_10_flag = kwargs["esc_10_flag"]
        self.file_column = kwargs["file_column"]
        self.label_column = kwargs["label_column"]
        self.sampling_rate = kwargs["sampling_rate"]
        self.new_sampling_rate = kwargs["new_sampling_rate"]
        self.sample_length_seconds = kwargs["sample_length_seconds"]

        # Filter dataframe based on esc_10_flag and data_type
        if self.esc_10_flag:
            self.data_frame = self.data_frame.loc[self.data_frame['esc10'] == True]

        if dataset == "train":
            self.data_frame = self.data_frame.loc[
                (self.data_frame['fold'] != self.validation_fold) & (self.data_frame['fold'] != self.testing_fold)]
        elif dataset == "val":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.validation_fold]
        elif dataset == "test":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.testing_fold]

        # Get unique categories from the filtered dataframe
        self.categories = sorted(self.data_frame[self.label_column].unique())

        # Initialize lists to hold file names, labels, and folder numbers
        self.file_names = []
        self.labels = []

        # Initialize dictionaries for category-to-index and index-to-category mapping
        self.category_to_index = {}
        self.index_to_category = {}

        for i, category in enumerate(self.categories):
            self.category_to_index[category] = i
            self.index_to_category[i] = category

        # Populate file names and labels lists by iterating through the dataframe
        for ind in tqdm(range(len(self.data_frame))):
            row = self.data_frame.iloc[ind]
            file_path = self.data_directory / "audio" / row[self.file_column]
            self.file_names.append(file_path)
            self.labels.append(self.category_to_index[row[self.label_column]])

        self.resampler = torchaudio.transforms.Resample(self.sampling_rate, self.new_sampling_rate)

        # Window size for rolling window sample splits (unfold method)
        if self.sample_length_seconds == 2:
            self.window_size = self.new_sampling_rate * 2
            self.step_size = int(self.new_sampling_rate * 0.75)
        else:
            self.window_size = self.new_sampling_rate
            self.step_size = int(self.new_sampling_rate * 0.5)

    def __getitem__(self, index):
        # Split audio files with overlap, pass as stacked tensors tensor with a single label
        path = self.file_names[index]
        audio_file = torchaudio.load(str(path), format=None, normalize=True)
        audio_tensor = self.resampler(audio_file[0])
        splits = audio_tensor.unfold(1, self.window_size, self.step_size)
        samples = splits.permute(1, 0, 2)
        return samples, self.labels[index]

    def __len__(self):
        return len(self.file_names)

class CustomDataModule(pl.LightningDataModule):
    def __init__(self, **kwargs):
        # Initialize the CustomDataModule with batch size, number of workers, and other parameters
        super().__init__()
        self.batch_size = kwargs["batch_size"]
        self.num_workers = kwargs["num_workers"]
        self.data_module_kwargs = kwargs

    def setup(self, stage=None):
        # Define datasets for training, validation, and testing during Lightning setup

        # If in 'fit' or None stage, create training and validation datasets
        if stage == 'fit' or stage is None:
            self.training_dataset = CustomDataset(dataset="train", **self.data_module_kwargs)
            self.validation_dataset = CustomDataset(dataset="val", **self.data_module_kwargs)

        # If in 'test' or None stage, create testing dataset
        if stage == 'test' or stage is None:
            self.testing_dataset = CustomDataset(dataset="test", **self.data_module_kwargs)

    def train_dataloader(self):
        # Return DataLoader for training dataset
        return DataLoader(self.training_dataset,
                          batch_size=self.batch_size,
                          shuffle=True,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def val_dataloader(self):
        # Return DataLoader for validation dataset
        return DataLoader(self.validation_dataset,
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def test_dataloader(self):
        # Return DataLoader for testing dataset
        return DataLoader(self.testing_dataset,
                          batch_size=32,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def collate_function(self, data):
        """
        Collate function to process a batch of examples and labels.

        Args:
            data: a tuple of 2 tuples with (example, label) where
                example are the split 1 second sub-frame audio tensors per file
                label = the label

        Returns:
            A list containing examples (concatenated tensors) and labels (flattened tensor).
        """
        examples, labels = zip(*data)
        # examples = torch.cat(examples)
        examples = torch.stack(examples)
        examples = examples.reshape(examples.size(0),1,-1)
        labels = torch.flatten(torch.tensor(labels))

        return [examples, labels]

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, roc_curve
import wandb

import torchvision
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader, TensorDataset
from sklearn.model_selection import train_test_split

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("Device:", device)

class Architecture1(nn.Module):
    def __init__(self):
        super(Architecture1, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm1d(16)  # BatchNorm1d after first conv layer
        self.conv2 = nn.Conv1d(16, 8, kernel_size=5, stride=2, padding=2)
        self.bn2 = nn.BatchNorm1d(8)  # BatchNorm1d after second conv layer

        self.dropout1 = nn.Dropout(p=0.2)  # Dropout after maxpooling

        self.conv3 = nn.Conv1d(8, 4, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d(4)  # BatchNorm1d after third conv layer
        self.conv4 = nn.Conv1d(4, 2, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm1d(2)

        # self.dropout2 = nn.Dropout(p=0.2)  # Dropout after maxpooling

        # self.conv5 = nn.Conv1d(2, 1, kernel_size=3, stride=1, padding=1)
        # self.bn5 = nn.BatchNorm1d(1)
        self.fc1 = nn.Linear(1124, 10)
        # self.fc2 = nn.Linear(600, 10)
        # self.fc3 = nn.Linear(2250, 10)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.max_pool1d(F.relu(self.bn2(self.conv2(x))), 8)
        x = self.dropout1(x)

        x = F.relu(self.bn3(self.conv3(x)))
        x = F.max_pool1d(F.relu(self.bn4(self.conv4(x))), 8)
        # x = self.dropout2(x)

        # x = F.max_pool1d(F.relu(self.bn5(self.conv5(x))), 8)
        x = x.view(x.size(0), -1)
        # x = F.relu(self.fc1(x))  # Add ReLU after fc1
        # x = F.relu(self.fc2(x))  # Add ReLU after fc2
        x = F.softmax(self.fc1(x), dim=1)  # Apply softmax on final layer
        return x

learning_rates = [0.001, 0.05]
optimizers = ['Adam', 'SGD']

#Model1

for optimizer_type in optimizers:
    for lr_type in learning_rates:

        all_test_accuracy = []
        all_validation_accuracy = []
        valid_samples = [2,3,4,5]

        for i in valid_samples:
            # Data Setup
            test_samp = 1 #Do not change this!!
            valid_samp = i # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
            batch_size = 32 # Free to change
            num_workers = 2 # Free to change
            custom_data_module = CustomDataModule(batch_size=batch_size,
                                                num_workers=num_workers,
                                                data_directory=path,
                                                data_frame=df,
                                                validation_fold=valid_samp,
                                                testing_fold=test_samp,  # set to 0 for no test set
                                                esc_10_flag=True,
                                                file_column='filename',
                                                label_column='category',
                                                sampling_rate=44100,
                                                new_sampling_rate=16000,  # new sample rate for input
                                                sample_length_seconds=1  # new length of input in seconds
                                                )

            custom_data_module.setup()

            # Hyperparameters
            num_classes = 10
            lr = lr_type
            epochs = 100
            # Model, Optimizer, Loss function
            model1 = Architecture1().to(device)
            # model2 = Architecture2()
            # optimizer = optim.Adam(model1.parameters(), lr=lr)
            if optimizer_type == 'Adam':
                optimizer = optim.Adam(model1.parameters(), lr=lr)
            elif optimizer_type == 'SGD':
                optimizer = optim.SGD(model1.parameters(), lr=lr)

            criterion = nn.CrossEntropyLoss()

            # WandB initialization
            wandb.init(project="Architecture1_Model1_final_light", name=f"{optimizer_type}, {lr} lr, {i} fold")

            # Training loop
            train_acc_track = []
            val_acc_track = []
            train_loss_track = []
            val_loss_track = []

            for epoch in range(epochs):
                model1.train()
                running_loss = 0.0
                correct = 0
                total = 0

                for data, target in custom_data_module.train_dataloader():
                    data, target = data.to(device), target.to(device)
                    optimizer.zero_grad()
                    output = model1(data)
                    loss = criterion(output, target)
                    loss.backward()
                    optimizer.step()

                    running_loss += loss.item()
                    _, predicted = output.max(1)

                    total += target.size(0)
                    correct += predicted.eq(target).sum().item()

                train_loss = running_loss / len(custom_data_module.train_dataloader())
                train_acc = 100. * correct / total

                train_loss_track.append(train_loss)
                train_acc_track.append(train_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')

                # Validation
                model1.eval()
                val_loss = 0.0
                val_correct = 0
                val_total = 0

                with torch.no_grad():
                    for data, target in custom_data_module.val_dataloader():
                        data, target = data.to(device), target.to(device)
                        output = model1(data)
                        loss = criterion(output, target)
                        val_loss += loss.item()
                        _, predicted = output.max(1)

                        val_total += target.size(0)
                        val_correct += predicted.eq(target).sum().item()

                val_loss /= len(custom_data_module.val_dataloader())
                val_acc = 100. * val_correct / val_total

                val_loss_track.append(val_loss)
                val_acc_track.append(val_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')

                # # Logging
                wandb.log({"Train Loss": train_loss, "Train Accuracy": train_acc, "Validation Loss": val_loss, "Val Accuracy": val_acc, "Learning rate": lr, "Optimizer": optimizer_type})


            all_validation_accuracy.append(val_acc)

            # Testing
            model1.eval()
            test_correct = 0
            test_total = 0
            all_labels_test = []
            all_preds_test = []
            all_probabilities = []

            with torch.no_grad():
                for data, target in custom_data_module.test_dataloader():
                    data, target = data.to(device), target.to(device)
                    output = model1(data)
                    all_probabilities.extend(output.cpu().numpy())
                    _, predicted = output.max(1)
                    test_total += target.size(0)
                    test_correct += predicted.eq(target).sum().item()
                    all_labels_test.extend(target.cpu().numpy())
                    all_preds_test.extend(predicted.cpu().numpy())

            test_acc = 100. * test_correct / test_total
            print(f'{optimizer_type}, {lr} lr, {i} fold, Test Accuracy: {test_acc:.2f}%')
            # print(f'Test Accuracy: {test_acc:.2f}%')
            all_test_accuracy.append(test_acc)

            # Confusion Matrix for test set
            cm = confusion_matrix(all_labels_test, all_preds_test)
            plt.figure(figsize=(7, 5))
            sns.heatmap(cm, annot=True,fmt = 'd', cmap='Blues')
            plt.title(f'{optimizer_type}, {lr} lr, {i} fold, Confusion Matrix')
            # plt.title(f'Confusion Matrix')
            plt.xlabel("predicted class",size=10)
            plt.ylabel("actual class",size=10)
            # plt.show()

            # # Confusion Matrix
            # cm = wandb.plot.confusion_matrix(
            #     y_true = all_labels_test, preds = all_preds_test
            # )
            wandb.log({"Confusion Matrix": wandb.Image(plt)})
            plt.show()

            # Calculate overall F1 score
            overall_f1_score = f1_score(all_labels_test, all_preds_test, average='weighted')

            # print(f'Overall F1 Score: {overall_f1_score}')
            print(f'{optimizer_type}, {lr} lr, {i} fold, Overall F1 Score: {overall_f1_score}')

            wandb.summary["F1 score"] = overall_f1_score

            # roc curve for classes
            fpr = {}
            tpr = {}
            thresh ={}
            n_class = 10

            for j in range(n_class):
                fpr[j], tpr[j], thresh[j] = roc_curve(all_labels_test, np.array(all_probabilities)[:,j], pos_label=j)
                plt.plot(fpr[j], tpr[j], label = f'{j} vs rest',color = np.random.choice(['r','g','b','y','c','m','k']))
            plt.legend()
            # plt.title("AUC-ROC curve")
            plt.title(f'{optimizer_type} Optim, {lr} lr, {i} fold, AUC-ROC curve')


            # # roc curve for classes
            # roc_curves = {}
            # n_class = 10  # Assuming you have 10 classes, adjust accordingly

            # for j in range(n_class):
            #     fpr[j], tpr[j], _ = roc_curve(all_labels_test, np.array(all_probabilities)[:, j], pos_label=j)
            #     roc_curves[j] = {"fpr": fpr[j], "tpr": tpr[j]}

            wandb.log({"ROC curve": wandb.Image(plt)})
            plt.show()

            wandb.summary["Test accuracy"] = test_acc
            wandb.finish()

        print(f'{optimizer_type}, {lr} lr, Mean validation accuracy: {mean(all_validation_accuracy)}')
        print(f'{optimizer_type}, {lr} lr, Best test accuracy: {max(all_test_accuracy)}')

def numel(model1: torch.nn.Module, only_trainable: bool = False):

    parameters = list(model1.parameters())
    if only_trainable:
        parameters = [p for p in parameters if p.requires_grad]
    unique = {p.data_ptr(): p for p in parameters}.values()
    return sum(p.numel() for p in unique)

numel(model1,only_trainable=True),numel(model1,only_trainable=False)-numel(model1,only_trainable=True)

class multi_head_self_attention(nn.Module):
    def __init__(self, embed_dim, n_heads, attn_mask=None):
        super(multi_head_self_attention,self).__init__()
        # print(embed_dim,n_heads)
        # print(embed_dim,n_heads.shape)
        assert embed_dim % n_heads == 0  # Ensure divisibility

        self.head_dim = embed_dim // n_heads  # Key/query dimension per head
        self.n_heads = n_heads
        self.embed_dim = embed_dim

        # Linear projections for queries, keys, and values
        self.linear_q = nn.Linear(self.embed_dim, self.embed_dim * self.n_heads)
        self.linear_k = nn.Linear(self.embed_dim, self.embed_dim * self.n_heads)
        self.linear_v = nn.Linear(self.embed_dim, self.embed_dim * self.n_heads)

        self.unifyheads = nn.Linear(self.n_heads * self.embed_dim, self.embed_dim)

    def forward(self, x):
        # print(x.shape)
        batches, N, d = x.size()
        h = self.n_heads

        k = self.linear_k(x).view(batches ,N, h, d)
        q = self.linear_q(x).view(batches ,N, h, d)
        v = self.linear_v(x).view(batches ,N, h, d)

        k = k.transpose(1, 2).contiguous().view(batches * h, N, d)
        q = q.transpose(1, 2).contiguous().view(batches * h, N, d)
        v = v.transpose(1, 2).contiguous().view(batches * h, N, d)

        # Scaled dot-product attention
        scores = torch.bmm(q, k.transpose(-2, -1)) / np.sqrt(d)

        # if attn_mask is not None:
        #     scores = scores.masked_fill(attn_mask == 0, -1e9)

        attn = F.softmax(scores, dim=-1)
        output = torch.bmm(attn, v).view(batches, h, N, d)

        # Combine heads and return output
        output = output.transpose(1, 2).contiguous().view(batches, N, h * d)
        return self.unifyheads(output)
        # return output.view(x.size(0), self.head_dim * self.n_heads)

#Model2 - Heads=1

class Architecture2(nn.Module):
    def __init__(self):
        super(Architecture2, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, stride=1, padding=3)
        self.bn1 = nn.BatchNorm1d(16)  # BatchNorm1d after first conv layer
        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)
        self.bn2 = nn.BatchNorm1d(32)  # BatchNorm1d after second conv layer
        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d(64)  # BatchNorm1d after third conv layer
        self.conv4 = nn.Conv1d(64, 48, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm1d(48)
        self.ad1 = nn.AdaptiveAvgPool2d((47, 48))
        # self.conv5 = nn.Conv1d(48, 16, kernel_size=3, stride=1, padding=1)
        # self.bn5 = nn.BatchNorm1d(16)
        self.fc1 = nn.Linear(48, 48)
        self.fc2 = nn.Linear(48, 48)
        self.fc3= nn.Linear(48, 10)
        # self.fc3 = nn.Linear(2250, 10)

        self.multi_head_self_attention = multi_head_self_attention(48, 1)
        self.multi_head_self_attention2 = multi_head_self_attention(48, 1)
        self.attention_blocks = [(self.multi_head_self_attention, self.fc1),(self.multi_head_self_attention2, self.fc2) ]

    def forward(self, x):
        # x=x.float()
        x = F.max_pool1d(F.relu(self.bn1(self.conv1(x))), 12)
        x = F.max_pool1d(F.relu(self.bn2(self.conv2(x))), 8)
        x = F.max_pool1d(F.relu(self.bn3(self.conv3(x))), 4)
        x = F.max_pool1d(F.relu(self.bn4(self.conv4(x))), 2)
        x = self.ad1(x)
        # x = F.max_pool1d(F.relu(self.bn5(self.conv5(x))), 16)
        # x = x.view(x.size(0), -1)
        # x = F.relu(self.fc1(x))  # Add ReLU after fc1
        # x = F.relu(self.fc2(x))  # Add ReLU after fc2
        # x = F.softmax(self.fc2(x), dim=1)  # Apply softmax on final layer

        # print(x.shape)
        self.cls_token = nn.Parameter(torch.zeros(1, 48).to(device))
        x = torch.cat((self.cls_token.expand(x.size(0), 1, -1), x), dim=1)
        x = x.to(device)
        # x = torch.cat((cls_token,x), dim=1)
        # print(x.shape)

        #Multi-head self attention
        for blocks in self.attention_blocks:

            #Positional encoding
            x = x + torch.tensor(self.getPositionEncoding(48, 48),dtype = x.dtype).to(device)

            multihead = blocks[0]
            fc = blocks[1]

            y = multihead(x)
            x = x + y

            #layer norm
            x = self.layer_normalization(x)

            #mlp
            y = fc(x)#self.mlp_layer(x)
            x = x + y

            #layer norm
            x = self.layer_normalization(x)

        #final mlp layer for classification
        x = torch.flatten(x[:,0],1)
        # x = self.fc2(x)#self.mlp_layer_final(x)
        x = F.softmax(self.fc3(x), dim=1)  # Apply softmax on final layer

        # print(x.shape)
        return x

    def getPositionEncoding(self, seq_len, d, n=10000):
        P = np.zeros((seq_len, d))
        for k in range(0,seq_len-1):
            for i in np.arange(int(d/2)):
                denominator = np.power(n, 2*i/d)
                P[k+1, 2*i] = np.sin(k/denominator)
                P[k+1, 2*i+1] = np.cos(k/denominator)
        return P

    def layer_normalization(self, x, eps=1e-6):
        mean = torch.mean(x, dim=-1, keepdim=True)
        std = torch.std(x, dim=-1, keepdim=True) + eps
        return (x - mean) / std

learning_rates = [0.001, 0.05]
optimizers = ['Adam', 'SGD']

for optimizer_type in optimizers:
    for lr_type in learning_rates:

        all_test_accuracy = []
        all_validation_accuracy = []
        valid_samples = [2,3,4,5]

        for i in valid_samples:
            # Data Setup
            test_samp = 1 #Do not change this!!
            valid_samp = i # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
            batch_size = 32 # Free to change
            num_workers = 2 # Free to change
            custom_data_module = CustomDataModule(batch_size=batch_size,
                                                num_workers=num_workers,
                                                data_directory=path,
                                                data_frame=df,
                                                validation_fold=valid_samp,
                                                testing_fold=test_samp,  # set to 0 for no test set
                                                esc_10_flag=True,
                                                file_column='filename',
                                                label_column='category',
                                                sampling_rate=44100,
                                                new_sampling_rate=16000,  # new sample rate for input
                                                sample_length_seconds=1  # new length of input in seconds
                                                )

            custom_data_module.setup()

            # Hyperparameters
            num_classes = 10
            lr = lr_type
            epochs = 100
            # Model, Optimizer, Loss function
            model2 = Architecture2().to(device)
            # model2 = Architecture2()
            # optimizer = optim.Adam(model2.parameters(), lr=lr)
            if optimizer_type == 'Adam':
                optimizer = optim.Adam(model2.parameters(), lr=lr)
            elif optimizer_type == 'SGD':
                optimizer = optim.SGD(model2.parameters(), lr=lr)

            criterion = nn.CrossEntropyLoss()

            # WandB initialization
            wandb.init(project="Architecture2_model2_Head1_final_light", name=f"{optimizer_type}, {lr} lr, {i} fold")

            # Training loop
            train_acc_track = []
            val_acc_track = []
            train_loss_track = []
            val_loss_track = []

            for epoch in range(epochs):
                model2.train()
                running_loss = 0.0
                correct = 0
                total = 0

                for data, target in custom_data_module.train_dataloader():
                    data, target = data.to(device), target.to(device)
                    optimizer.zero_grad()
                    output = model2(data)
                    loss = criterion(output, target)
                    loss.backward()
                    optimizer.step()

                    running_loss += loss.item()
                    _, predicted = output.max(1)

                    total += target.size(0)
                    correct += predicted.eq(target).sum().item()

                train_loss = running_loss / len(custom_data_module.train_dataloader())
                train_acc = 100. * correct / total

                train_loss_track.append(train_loss)
                train_acc_track.append(train_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')

                # Validation
                model2.eval()
                val_loss = 0.0
                val_correct = 0
                val_total = 0

                with torch.no_grad():
                    for data, target in custom_data_module.val_dataloader():
                        data, target = data.to(device), target.to(device)
                        output = model2(data)
                        loss = criterion(output, target)
                        val_loss += loss.item()
                        _, predicted = output.max(1)

                        val_total += target.size(0)
                        val_correct += predicted.eq(target).sum().item()

                val_loss /= len(custom_data_module.val_dataloader())
                val_acc = 100. * val_correct / val_total

                val_loss_track.append(val_loss)
                val_acc_track.append(val_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')

                # # Logging
                wandb.log({"Train Loss": train_loss, "Train Accuracy": train_acc, "Validation Loss": val_loss, "Val Accuracy": val_acc, "Learning rate": lr, "Optimizer": optimizer_type})


            all_validation_accuracy.append(val_acc)

            # Testing
            model2.eval()
            test_correct = 0
            test_total = 0
            all_labels_test = []
            all_preds_test = []
            all_probabilities = []

            with torch.no_grad():
                for data, target in custom_data_module.test_dataloader():
                    data, target = data.to(device), target.to(device)
                    output = model2(data)
                    all_probabilities.extend(output.cpu().numpy())
                    _, predicted = output.max(1)
                    test_total += target.size(0)
                    test_correct += predicted.eq(target).sum().item()
                    all_labels_test.extend(target.cpu().numpy())
                    all_preds_test.extend(predicted.cpu().numpy())

            test_acc = 100. * test_correct / test_total
            print(f'{optimizer_type}, {lr} lr, {i} fold, Test Accuracy: {test_acc:.2f}%')
            # print(f'Test Accuracy: {test_acc:.2f}%')
            all_test_accuracy.append(test_acc)

            # Confusion Matrix for test set
            cm = confusion_matrix(all_labels_test, all_preds_test)
            plt.figure(figsize=(7, 5))
            sns.heatmap(cm, annot=True,fmt = 'd', cmap='Blues')
            plt.title(f'{optimizer_type}, {lr} lr, {i} fold, Confusion Matrix')
            # plt.title(f'Confusion Matrix')
            plt.xlabel("predicted class",size=10)
            plt.ylabel("actual class",size=10)
            # plt.show()

            # # Confusion Matrix
            # cm = wandb.plot.confusion_matrix(
            #     y_true = all_labels_test, preds = all_preds_test
            # )
            wandb.log({"Confusion Matrix": wandb.Image(plt)})
            plt.show()

            # Calculate overall F1 score
            overall_f1_score = f1_score(all_labels_test, all_preds_test, average='weighted')

            # print(f'Overall F1 Score: {overall_f1_score}')
            print(f'{optimizer_type}, {lr} lr, {i} fold, Overall F1 Score: {overall_f1_score}')

            wandb.summary["F1 score"] = overall_f1_score

            # roc curve for classes
            fpr = {}
            tpr = {}
            thresh ={}
            n_class = 10

            for j in range(n_class):
                fpr[j], tpr[j], thresh[j] = roc_curve(all_labels_test, np.array(all_probabilities)[:,j], pos_label=j)
                plt.plot(fpr[j], tpr[j], label = f'{j} vs rest',color = np.random.choice(['r','g','b','y','c','m','k']))
            plt.legend()
            # plt.title("AUC-ROC curve")
            plt.title(f'{optimizer_type} Optim, {lr} lr, {i} fold, AUC-ROC curve')


            # # roc curve for classes
            # roc_curves = {}
            # n_class = 10  # Assuming you have 10 classes, adjust accordingly

            # for j in range(n_class):
            #     fpr[j], tpr[j], _ = roc_curve(all_labels_test, np.array(all_probabilities)[:, j], pos_label=j)
            #     roc_curves[j] = {"fpr": fpr[j], "tpr": tpr[j]}

            wandb.log({"ROC curve": wandb.Image(plt)})
            plt.show()

            wandb.summary["Test accuracy"] = test_acc
            wandb.finish()

        print(f'{optimizer_type}, {lr} lr, Mean validation accuracy: {mean(all_validation_accuracy)}')
        print(f'{optimizer_type}, {lr} lr, Best test accuracy: {max(all_test_accuracy)}')

#Architecture2 - Model2 - head = 2

class Architecture2(nn.Module):
    def __init__(self):
        super(Architecture2, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, stride=1, padding=3)
        self.bn1 = nn.BatchNorm1d(16)  # BatchNorm1d after first conv layer
        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)
        self.bn2 = nn.BatchNorm1d(32)  # BatchNorm1d after second conv layer
        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d(64)  # BatchNorm1d after third conv layer
        self.conv4 = nn.Conv1d(64, 48, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm1d(48)
        self.ad1 = nn.AdaptiveAvgPool2d((47, 48))
        # self.conv5 = nn.Conv1d(48, 16, kernel_size=3, stride=1, padding=1)
        # self.bn5 = nn.BatchNorm1d(16)
        self.fc1 = nn.Linear(48, 48)
        self.fc2 = nn.Linear(48, 48)
        self.fc3= nn.Linear(48, 10)
        # self.fc3 = nn.Linear(2250, 10)

        self.multi_head_self_attention = multi_head_self_attention(48, 2)
        self.multi_head_self_attention2 = multi_head_self_attention(48, 2)
        self.attention_blocks = [(self.multi_head_self_attention, self.fc1),(self.multi_head_self_attention2, self.fc2) ]

    def forward(self, x):
        # x=x.float()
        x = F.max_pool1d(F.relu(self.bn1(self.conv1(x))), 12)
        x = F.max_pool1d(F.relu(self.bn2(self.conv2(x))), 8)
        x = F.max_pool1d(F.relu(self.bn3(self.conv3(x))), 4)
        x = F.max_pool1d(F.relu(self.bn4(self.conv4(x))), 2)
        x = self.ad1(x)
        # x = F.max_pool1d(F.relu(self.bn5(self.conv5(x))), 16)
        # x = x.view(x.size(0), -1)
        # x = F.relu(self.fc1(x))  # Add ReLU after fc1
        # x = F.relu(self.fc2(x))  # Add ReLU after fc2
        # x = F.softmax(self.fc2(x), dim=1)  # Apply softmax on final layer

        # print(x.shape)
        self.cls_token = nn.Parameter(torch.zeros(1, 48).to(device))
        x = torch.cat((self.cls_token.expand(x.size(0), 1, -1), x), dim=1)
        x = x.to(device)
        # x = torch.cat((cls_token,x), dim=1)
        # print(x.shape)

        #Multi-head self attention
        for blocks in self.attention_blocks:

            #Positional encoding
            x = x + torch.tensor(self.getPositionEncoding(48, 48),dtype = x.dtype).to(device)

            multihead = blocks[0]
            fc = blocks[1]

            y = multihead(x)
            x = x + y

            #layer norm
            x = self.layer_normalization(x)

            #mlp
            y = fc(x)#self.mlp_layer(x)
            x = x + y

            #layer norm
            x = self.layer_normalization(x)

        #final mlp layer for classification
        x = torch.flatten(x[:,0],1)
        # x = self.fc2(x)#self.mlp_layer_final(x)
        x = F.softmax(self.fc3(x), dim=1)  # Apply softmax on final layer

        # print(x.shape)
        return x

    def getPositionEncoding(self, seq_len, d, n=10000):
        P = np.zeros((seq_len, d))
        for k in range(0,seq_len-1):
            for i in np.arange(int(d/2)):
                denominator = np.power(n, 2*i/d)
                P[k+1, 2*i] = np.sin(k/denominator)
                P[k+1, 2*i+1] = np.cos(k/denominator)
        return P

    def layer_normalization(self, x, eps=1e-6):
        mean = torch.mean(x, dim=-1, keepdim=True)
        std = torch.std(x, dim=-1, keepdim=True) + eps
        return (x - mean) / std

learning_rates = [0.001, 0.05]
optimizers = ['Adam', 'SGD']

for optimizer_type in optimizers:
    for lr_type in learning_rates:

        all_test_accuracy = []
        all_validation_accuracy = []
        valid_samples = [2,3,4,5]

        for i in valid_samples:
            # Data Setup
            test_samp = 1 #Do not change this!!
            valid_samp = i # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
            batch_size = 32 # Free to change
            num_workers = 2 # Free to change
            custom_data_module = CustomDataModule(batch_size=batch_size,
                                                num_workers=num_workers,
                                                data_directory=path,
                                                data_frame=df,
                                                validation_fold=valid_samp,
                                                testing_fold=test_samp,  # set to 0 for no test set
                                                esc_10_flag=True,
                                                file_column='filename',
                                                label_column='category',
                                                sampling_rate=44100,
                                                new_sampling_rate=16000,  # new sample rate for input
                                                sample_length_seconds=1  # new length of input in seconds
                                                )

            custom_data_module.setup()

            # Hyperparameters
            num_classes = 10
            lr = lr_type
            epochs = 100
            # Model, Optimizer, Loss function
            model2 = Architecture2().to(device)
            # model2 = Architecture2()
            # optimizer = optim.Adam(model2.parameters(), lr=lr)
            if optimizer_type == 'Adam':
                optimizer = optim.Adam(model2.parameters(), lr=lr)
            elif optimizer_type == 'SGD':
                optimizer = optim.SGD(model2.parameters(), lr=lr)

            criterion = nn.CrossEntropyLoss()

            # WandB initialization
            wandb.init(project="Architecture2_model2_Head2_final_light", name=f"{optimizer_type}, {lr} lr, {i} fold")

            # Training loop
            train_acc_track = []
            val_acc_track = []
            train_loss_track = []
            val_loss_track = []

            for epoch in range(epochs):
                model2.train()
                running_loss = 0.0
                correct = 0
                total = 0

                for data, target in custom_data_module.train_dataloader():
                    data, target = data.to(device), target.to(device)
                    optimizer.zero_grad()
                    output = model2(data)
                    loss = criterion(output, target)
                    loss.backward()
                    optimizer.step()

                    running_loss += loss.item()
                    _, predicted = output.max(1)

                    total += target.size(0)
                    correct += predicted.eq(target).sum().item()

                train_loss = running_loss / len(custom_data_module.train_dataloader())
                train_acc = 100. * correct / total

                train_loss_track.append(train_loss)
                train_acc_track.append(train_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')

                # Validation
                model2.eval()
                val_loss = 0.0
                val_correct = 0
                val_total = 0

                with torch.no_grad():
                    for data, target in custom_data_module.val_dataloader():
                        data, target = data.to(device), target.to(device)
                        output = model2(data)
                        loss = criterion(output, target)
                        val_loss += loss.item()
                        _, predicted = output.max(1)

                        val_total += target.size(0)
                        val_correct += predicted.eq(target).sum().item()

                val_loss /= len(custom_data_module.val_dataloader())
                val_acc = 100. * val_correct / val_total

                val_loss_track.append(val_loss)
                val_acc_track.append(val_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')

                # # Logging
                wandb.log({"Train Loss": train_loss, "Train Accuracy": train_acc, "Validation Loss": val_loss, "Val Accuracy": val_acc, "Learning rate": lr, "Optimizer": optimizer_type})


            all_validation_accuracy.append(val_acc)

            # Testing
            model2.eval()
            test_correct = 0
            test_total = 0
            all_labels_test = []
            all_preds_test = []
            all_probabilities = []

            with torch.no_grad():
                for data, target in custom_data_module.test_dataloader():
                    data, target = data.to(device), target.to(device)
                    output = model2(data)
                    all_probabilities.extend(output.cpu().numpy())
                    _, predicted = output.max(1)
                    test_total += target.size(0)
                    test_correct += predicted.eq(target).sum().item()
                    all_labels_test.extend(target.cpu().numpy())
                    all_preds_test.extend(predicted.cpu().numpy())

            test_acc = 100. * test_correct / test_total
            print(f'{optimizer_type}, {lr} lr, {i} fold, Test Accuracy: {test_acc:.2f}%')
            # print(f'Test Accuracy: {test_acc:.2f}%')
            all_test_accuracy.append(test_acc)

            # Confusion Matrix for test set
            cm = confusion_matrix(all_labels_test, all_preds_test)
            plt.figure(figsize=(7, 5))
            sns.heatmap(cm, annot=True,fmt = 'd', cmap='Blues')
            plt.title(f'{optimizer_type}, {lr} lr, {i} fold, Confusion Matrix')
            # plt.title(f'Confusion Matrix')
            plt.xlabel("predicted class",size=10)
            plt.ylabel("actual class",size=10)
            # plt.show()

            # # Confusion Matrix
            # cm = wandb.plot.confusion_matrix(
            #     y_true = all_labels_test, preds = all_preds_test
            # )
            wandb.log({"Confusion Matrix": wandb.Image(plt)})
            plt.show()

            # Calculate overall F1 score
            overall_f1_score = f1_score(all_labels_test, all_preds_test, average='weighted')

            # print(f'Overall F1 Score: {overall_f1_score}')
            print(f'{optimizer_type}, {lr} lr, {i} fold, Overall F1 Score: {overall_f1_score}')

            wandb.summary["F1 score"] = overall_f1_score

            # roc curve for classes
            fpr = {}
            tpr = {}
            thresh ={}
            n_class = 10

            for j in range(n_class):
                fpr[j], tpr[j], thresh[j] = roc_curve(all_labels_test, np.array(all_probabilities)[:,j], pos_label=j)
                plt.plot(fpr[j], tpr[j], label = f'{j} vs rest',color = np.random.choice(['r','g','b','y','c','m','k']))
            plt.legend()
            # plt.title("AUC-ROC curve")
            plt.title(f'{optimizer_type} Optim, {lr} lr, {i} fold, AUC-ROC curve')


            # # roc curve for classes
            # roc_curves = {}
            # n_class = 10  # Assuming you have 10 classes, adjust accordingly

            # for j in range(n_class):
            #     fpr[j], tpr[j], _ = roc_curve(all_labels_test, np.array(all_probabilities)[:, j], pos_label=j)
            #     roc_curves[j] = {"fpr": fpr[j], "tpr": tpr[j]}

            wandb.log({"ROC curve": wandb.Image(plt)})
            plt.show()

            wandb.summary["Test accuracy"] = test_acc
            wandb.finish()

        print(f'{optimizer_type}, {lr} lr, Mean validation accuracy: {mean(all_validation_accuracy)}')
        print(f'{optimizer_type}, {lr} lr, Best test accuracy: {max(all_test_accuracy)}')

#Architecture2 - Model2 - Head =4

class Architecture2(nn.Module):
    def __init__(self):
        super(Architecture2, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, stride=1, padding=3)
        self.bn1 = nn.BatchNorm1d(16)  # BatchNorm1d after first conv layer
        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)
        self.bn2 = nn.BatchNorm1d(32)  # BatchNorm1d after second conv layer
        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d(64)  # BatchNorm1d after third conv layer
        self.conv4 = nn.Conv1d(64, 48, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm1d(48)
        self.ad1 = nn.AdaptiveAvgPool2d((47, 48))
        # self.conv5 = nn.Conv1d(48, 16, kernel_size=3, stride=1, padding=1)
        # self.bn5 = nn.BatchNorm1d(16)
        self.fc1 = nn.Linear(48, 48)
        self.fc2 = nn.Linear(48, 48)
        self.fc3= nn.Linear(48, 10)
        # self.fc3 = nn.Linear(2250, 10)

        self.multi_head_self_attention = multi_head_self_attention(48, 4)
        self.multi_head_self_attention2 = multi_head_self_attention(48, 4)
        self.attention_blocks = [(self.multi_head_self_attention, self.fc1),(self.multi_head_self_attention2, self.fc2) ]

    def forward(self, x):
        # x=x.float()
        x = F.max_pool1d(F.relu(self.bn1(self.conv1(x))), 12)
        x = F.max_pool1d(F.relu(self.bn2(self.conv2(x))), 8)
        x = F.max_pool1d(F.relu(self.bn3(self.conv3(x))), 4)
        x = F.max_pool1d(F.relu(self.bn4(self.conv4(x))), 2)
        x = self.ad1(x)
        # x = F.max_pool1d(F.relu(self.bn5(self.conv5(x))), 16)
        # x = x.view(x.size(0), -1)
        # x = F.relu(self.fc1(x))  # Add ReLU after fc1
        # x = F.relu(self.fc2(x))  # Add ReLU after fc2
        # x = F.softmax(self.fc2(x), dim=1)  # Apply softmax on final layer

        # print(x.shape)
        self.cls_token = nn.Parameter(torch.zeros(1, 48).to(device))
        x = torch.cat((self.cls_token.expand(x.size(0), 1, -1), x), dim=1)
        x = x.to(device)
        # x = torch.cat((cls_token,x), dim=1)
        # print(x.shape)

        #Multi-head self attention
        for blocks in self.attention_blocks:

            #Positional encoding
            x = x + torch.tensor(self.getPositionEncoding(48, 48),dtype = x.dtype).to(device)

            multihead = blocks[0]
            fc = blocks[1]

            y = multihead(x)
            x = x + y

            #layer norm
            x = self.layer_normalization(x)

            #mlp
            y = fc(x)#self.mlp_layer(x)
            x = x + y

            #layer norm
            x = self.layer_normalization(x)

        #final mlp layer for classification
        x = torch.flatten(x[:,0],1)
        # x = self.fc2(x)#self.mlp_layer_final(x)
        x = F.softmax(self.fc3(x), dim=1)  # Apply softmax on final layer

        # print(x.shape)
        return x

    def getPositionEncoding(self, seq_len, d, n=10000):
        P = np.zeros((seq_len, d))
        for k in range(0,seq_len-1):
            for i in np.arange(int(d/2)):
                denominator = np.power(n, 2*i/d)
                P[k+1, 2*i] = np.sin(k/denominator)
                P[k+1, 2*i+1] = np.cos(k/denominator)
        return P

    def layer_normalization(self, x, eps=1e-6):
        mean = torch.mean(x, dim=-1, keepdim=True)
        std = torch.std(x, dim=-1, keepdim=True) + eps
        return (x - mean) / std

learning_rates = [0.001, 0.05]
optimizers = ['Adam', 'SGD']

for optimizer_type in optimizers:
    for lr_type in learning_rates:

        all_test_accuracy = []
        all_validation_accuracy = []
        valid_samples = [2,3,4,5]

        for i in valid_samples:
            # Data Setup
            test_samp = 1 #Do not change this!!
            valid_samp = i # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
            batch_size = 32 # Free to change
            num_workers = 2 # Free to change
            custom_data_module = CustomDataModule(batch_size=batch_size,
                                                num_workers=num_workers,
                                                data_directory=path,
                                                data_frame=df,
                                                validation_fold=valid_samp,
                                                testing_fold=test_samp,  # set to 0 for no test set
                                                esc_10_flag=True,
                                                file_column='filename',
                                                label_column='category',
                                                sampling_rate=44100,
                                                new_sampling_rate=16000,  # new sample rate for input
                                                sample_length_seconds=1  # new length of input in seconds
                                                )

            custom_data_module.setup()

            # Hyperparameters
            num_classes = 10
            lr = lr_type
            epochs = 100
            # Model, Optimizer, Loss function
            model2 = Architecture2().to(device)
            # model2 = Architecture2()
            # optimizer = optim.Adam(model2.parameters(), lr=lr)
            if optimizer_type == 'Adam':
                optimizer = optim.Adam(model2.parameters(), lr=lr)
            elif optimizer_type == 'SGD':
                optimizer = optim.SGD(model2.parameters(), lr=lr)

            criterion = nn.CrossEntropyLoss()

            # WandB initialization
            wandb.init(project="Architecture2_model2_Head4_final_light", name=f"{optimizer_type}, {lr} lr, {i} fold")

            # Training loop
            train_acc_track = []
            val_acc_track = []
            train_loss_track = []
            val_loss_track = []

            for epoch in range(epochs):
                model2.train()
                running_loss = 0.0
                correct = 0
                total = 0

                for data, target in custom_data_module.train_dataloader():
                    data, target = data.to(device), target.to(device)
                    optimizer.zero_grad()
                    output = model2(data)
                    loss = criterion(output, target)
                    loss.backward()
                    optimizer.step()

                    running_loss += loss.item()
                    _, predicted = output.max(1)

                    total += target.size(0)
                    correct += predicted.eq(target).sum().item()

                train_loss = running_loss / len(custom_data_module.train_dataloader())
                train_acc = 100. * correct / total

                train_loss_track.append(train_loss)
                train_acc_track.append(train_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')

                # Validation
                model2.eval()
                val_loss = 0.0
                val_correct = 0
                val_total = 0

                with torch.no_grad():
                    for data, target in custom_data_module.val_dataloader():
                        data, target = data.to(device), target.to(device)
                        output = model2(data)
                        loss = criterion(output, target)
                        val_loss += loss.item()
                        _, predicted = output.max(1)

                        val_total += target.size(0)
                        val_correct += predicted.eq(target).sum().item()

                val_loss /= len(custom_data_module.val_dataloader())
                val_acc = 100. * val_correct / val_total

                val_loss_track.append(val_loss)
                val_acc_track.append(val_acc)

                if (epoch+1) % 10 == 0:
                    print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')
                # print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')

                # # Logging
                wandb.log({"Train Loss": train_loss, "Train Accuracy": train_acc, "Validation Loss": val_loss, "Val Accuracy": val_acc, "Learning rate": lr, "Optimizer": optimizer_type})


            all_validation_accuracy.append(val_acc)

            # Testing
            model2.eval()
            test_correct = 0
            test_total = 0
            all_labels_test = []
            all_preds_test = []
            all_probabilities = []

            with torch.no_grad():
                for data, target in custom_data_module.test_dataloader():
                    data, target = data.to(device), target.to(device)
                    output = model2(data)
                    all_probabilities.extend(output.cpu().numpy())
                    _, predicted = output.max(1)
                    test_total += target.size(0)
                    test_correct += predicted.eq(target).sum().item()
                    all_labels_test.extend(target.cpu().numpy())
                    all_preds_test.extend(predicted.cpu().numpy())

            test_acc = 100. * test_correct / test_total
            print(f'{optimizer_type}, {lr} lr, {i} fold, Test Accuracy: {test_acc:.2f}%')
            # print(f'Test Accuracy: {test_acc:.2f}%')
            all_test_accuracy.append(test_acc)

            # Confusion Matrix for test set
            cm = confusion_matrix(all_labels_test, all_preds_test)
            plt.figure(figsize=(7, 5))
            sns.heatmap(cm, annot=True,fmt = 'd', cmap='Blues')
            plt.title(f'{optimizer_type}, {lr} lr, {i} fold, Confusion Matrix')
            # plt.title(f'Confusion Matrix')
            plt.xlabel("predicted class",size=10)
            plt.ylabel("actual class",size=10)
            # plt.show()

            # # Confusion Matrix
            # cm = wandb.plot.confusion_matrix(
            #     y_true = all_labels_test, preds = all_preds_test
            # )
            wandb.log({"Confusion Matrix": wandb.Image(plt)})
            plt.show()

            # Calculate overall F1 score
            overall_f1_score = f1_score(all_labels_test, all_preds_test, average='weighted')

            # print(f'Overall F1 Score: {overall_f1_score}')
            print(f'{optimizer_type}, {lr} lr, {i} fold, Overall F1 Score: {overall_f1_score}')

            wandb.summary["F1 score"] = overall_f1_score

            # roc curve for classes
            fpr = {}
            tpr = {}
            thresh ={}
            n_class = 10

            for j in range(n_class):
                fpr[j], tpr[j], thresh[j] = roc_curve(all_labels_test, np.array(all_probabilities)[:,j], pos_label=j)
                plt.plot(fpr[j], tpr[j], label = f'{j} vs rest',color = np.random.choice(['r','g','b','y','c','m','k']))
            plt.legend()
            # plt.title("AUC-ROC curve")
            plt.title(f'{optimizer_type} Optim, {lr} lr, {i} fold, AUC-ROC curve')


            # # roc curve for classes
            # roc_curves = {}
            # n_class = 10  # Assuming you have 10 classes, adjust accordingly

            # for j in range(n_class):
            #     fpr[j], tpr[j], _ = roc_curve(all_labels_test, np.array(all_probabilities)[:, j], pos_label=j)
            #     roc_curves[j] = {"fpr": fpr[j], "tpr": tpr[j]}

            wandb.log({"ROC curve": wandb.Image(plt)})
            plt.show()

            wandb.summary["Test accuracy"] = test_acc
            wandb.finish()

        print(f'{optimizer_type}, {lr} lr, Mean validation accuracy: {mean(all_validation_accuracy)}')
        print(f'{optimizer_type}, {lr} lr, Best test accuracy: {max(all_test_accuracy)}')

def numel(model2: torch.nn.Module, only_trainable: bool = False):

    parameters = list(model2.parameters())
    if only_trainable:
        parameters = [p for p in parameters if p.requires_grad]
    unique = {p.data_ptr(): p for p in parameters}.values()
    return sum(p.numel() for p in unique)

numel(model2,only_trainable=True),numel(model2,only_trainable=False)-numel(model2,only_trainable=True)